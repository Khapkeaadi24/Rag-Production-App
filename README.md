ğŸ“š RAG Production App (Python)

A production-style Retrieval-Augmented Generation (RAG) application built with Python.
This project ingests PDFs, generates embeddings, stores them in Qdrant, orchestrates background jobs using Inngest, and provides a simple Streamlit UI for interaction.

ğŸš€ Features

ğŸ“„ PDF ingestion & chunking

ğŸ§  Embeddings pipeline (local embeddings â€“ no OpenAI dependency)

ğŸ—„ï¸ Vector storage using Qdrant

âš™ï¸ Background job orchestration with Inngest

ğŸŒ Streamlit-based UI

ğŸ§© Modular & production-friendly structure

ğŸ—ï¸ Project Structure
PythonProject1/
â”‚
â”œâ”€â”€ .venv/                  # Python virtual environment
â”œâ”€â”€ qdrant_storage/         # Persistent Qdrant storage (Docker volume)
â”‚   â”œâ”€â”€ aliases/
â”‚   â”œâ”€â”€ collections/
â”‚   â”œâ”€â”€ raft_state.json
â”‚   â””â”€â”€ .qdrant_fs_check
â”‚
â”œâ”€â”€ data_loader.py          # PDF loading, chunking & embedding logic
â”œâ”€â”€ vector_db.py            # Qdrant client & vector DB operations
â”œâ”€â”€ main.py                 # Core ingestion / orchestration logic
â”œâ”€â”€ streamlit_app.py        # Streamlit UI
â”œâ”€â”€ custom_types.py         # Shared type definitions
â”‚
â”œâ”€â”€ pyproject.toml          # Project metadata & dependencies
â”œâ”€â”€ uv.lock                 # Dependency lockfile (uv)
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â””â”€â”€ README.md

ğŸ§  Architecture Overview
PDF â†’ Chunking â†’ Embeddings â†’ Qdrant
                 â†“
             Inngest
                 â†“
            Streamlit UI


Embeddings: Generated locally using SentenceTransformers

Vector DB: Qdrant (Docker)

Background Jobs: Inngest

UI: Streamlit

LLM (optional): Groq (for generation, not embeddings)

âš™ï¸ Prerequisites

Make sure you have the following installed:

Python 3.10+

Docker Desktop (running, Linux containers)

Node.js (LTS) â€“ required for Inngest CLI

pip / uv

ğŸ§ª Environment Setup
1ï¸âƒ£ Create & activate virtual environment
python -m venv .venv
.venv\Scripts\activate

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt


or (if using uv):

uv sync

3ï¸âƒ£ Environment variables (.env)
INNGEST_API_BASE=http://127.0.0.1:8288


(No OpenAI key required if using local embeddings)

ğŸ—„ï¸ Start Qdrant (Docker)
docker run -d --name qdrantRagDb `
  -p 6333:6333 `
  -v ${PWD}\qdrant_storage:/qdrant/storage `
  qdrant/qdrant


Verify:

http://localhost:6333

âš¡ Start Inngest Dev Server
npx inngest-cli@latest dev `
  -u http://127.0.0.1:8000/api/inngest `
  --no-discovery

ğŸŒ Run Streamlit App

From the project root:

streamlit run streamlit_app.py


Open in browser:

http://localhost:8501

ğŸ“„ PDF Ingestion Flow

User provides a PDF path (via UI or event)

data_loader.py:

Loads PDF

Splits text into chunks

Generates embeddings

vector_db.py:

Stores vectors in Qdrant

Inngest:

Handles ingestion as background job

Streamlit:

Displays status & enables querying

ğŸ§  Embeddings Strategy

Local embeddings (SentenceTransformers)

No external API dependency

Faster & cheaper for production

Compatible with Qdrant

âœ… Why this is â€œProduction-Styleâ€

Background processing (Inngest)

Persistent vector storage (Qdrant)

Clean modular codebase

UI decoupled from ingestion

No hard dependency on OpenAI

ğŸ› ï¸ Future Improvements

ğŸ” Hybrid search (BM25 + vector)

ğŸ“Š Metadata-based filtering

ğŸ” Auth for Streamlit UI

ğŸ§ª Automated tests

â˜ï¸ Cloud deployment